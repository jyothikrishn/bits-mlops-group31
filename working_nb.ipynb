{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1203ec36-6aa5-451d-b4c9-a5b918cf86b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 12:29:18.856626: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-29 12:29:18.863836: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-29 12:29:18.952261: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-29 12:29:18.953989: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-29 12:29:19.839147: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "\n",
    "class MyModel:\n",
    "    def __init__(self):\n",
    "        # Load and prepare the California housing dataset\n",
    "        housing = fetch_california_housing()\n",
    "        X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "            housing.data, housing.target)\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "            X_train_full, y_train_full)\n",
    "\n",
    "        # Scale the features\n",
    "        self.scaler = StandardScaler()\n",
    "        X_train = self.scaler.fit_transform(X_train)\n",
    "        X_valid = self.scaler.transform(X_valid)\n",
    "        self.X_test = self.scaler.transform(X_test)\n",
    "        self.y_test = y_test\n",
    "\n",
    "        # Define the model architecture\n",
    "        self.model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "            tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "\n",
    "        # Compile the model\n",
    "        self.model.compile(loss=\"mean_squared_error\", optimizer=tf.keras.optimizers.SGD(learning_rate=1e-3))\n",
    "\n",
    "        # Fit the model\n",
    "        self.history = self.model.fit(X_train, y_train, epochs=20,\n",
    "                                      validation_data=(X_valid, y_valid))\n",
    "\n",
    "    def predict(self, input_data):\n",
    "        # Make predictions\n",
    "        return self.model.predict(input_data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdd18535-6664-4ad0-8820-7022584a9f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.2800 - val_loss: 0.8596\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.7232 - val_loss: 0.6382\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6306 - val_loss: 0.5977\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6001 - val_loss: 0.5735\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5786 - val_loss: 0.5549\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5614 - val_loss: 0.5407\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5475 - val_loss: 0.5286\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5369 - val_loss: 0.5185\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5274 - val_loss: 0.5115\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5197 - val_loss: 0.5038\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5130 - val_loss: 0.4976\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5074 - val_loss: 0.4928\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5028 - val_loss: 0.4871\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4986 - val_loss: 0.4835\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4949 - val_loss: 0.4795\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4914 - val_loss: 0.4769\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4884 - val_loss: 0.4733\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4854 - val_loss: 0.4705\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4829 - val_loss: 0.4677\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4803 - val_loss: 0.4662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/07/29 12:32:29 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp9ut6bvzo/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp9ut6bvzo/model/data/model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 68ms/step\n",
      "Sample inputs:\n",
      " [[-0.33763231 -0.20627036 -0.42778554 -0.20885401 -0.75208509 -0.11795677\n",
      "  -0.94377481  0.83431732]\n",
      " [-0.46735627  1.53609272  0.04164764 -0.04389985 -0.23715672 -0.01634571\n",
      "  -0.77565481  0.61525903]\n",
      " [-0.49443001 -0.60226197 -0.0790481   0.12039601 -1.09327015 -0.0377849\n",
      "   0.98493517 -0.62441176]\n",
      " [-0.79715409  0.26891957  0.14691952  0.08608743 -0.32357827 -0.02163727\n",
      "  -0.46743482 -0.44518224]\n",
      " [-0.43003842 -0.44386532 -0.38140846 -0.25478021 -0.4316052  -0.01074768\n",
      "  -0.72895481  0.95380366]]\n",
      "Predictions:\n",
      " [[1.9226772]\n",
      " [2.0630178]\n",
      " [1.2439072]\n",
      " [2.2743993]\n",
      " [1.3383068]]\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    my_model = MyModel()\n",
    "        # Set the MLflow tracking URI to the local server\n",
    "\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"learning_rate\", 1e-3)\n",
    "    mlflow.log_param(\"epochs\", 20)\n",
    "    \n",
    "    # Log metrics\n",
    "    for epoch, loss in enumerate(my_model.history.history['loss']):\n",
    "        mlflow.log_metric(\"loss\", loss, step=epoch)\n",
    "    for epoch, val_loss in enumerate(my_model.history.history['val_loss']):\n",
    "        mlflow.log_metric(\"val_loss\", val_loss, step=epoch)\n",
    "    \n",
    "    # Log the model\n",
    "    mlflow.tensorflow.log_model(my_model.model, \"model\")\n",
    "    \n",
    "    # Perform inferencing with some sample inputs from the test set\n",
    "    sample_inputs = my_model.X_test[:5]  # Take the first 5 samples from the test set\n",
    "    predictions = my_model.predict(sample_inputs)\n",
    "    \n",
    "    # Print the predictions\n",
    "    print(\"Sample inputs:\\n\", sample_inputs)\n",
    "    print(\"Predictions:\\n\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "708d4ffa-0028-47e5-8f45-ad33bd64ee98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jyothi/miniconda3/envs/myenv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading artifacts: 100%|██████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 1022.65it/s]\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "import tensorflow as tf\n",
    "from flask import Flask, request, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load the model from the MLflow Model Registry\n",
    "model_name = \"MyModel\"\n",
    "model_version = 1  # Specify the version of the model you want to use\n",
    "model = mlflow.tensorflow.load_model(f\"models:/{model_name}/{model_version}\")\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    data = request.get_json(force=True)\n",
    "    predictions = model.predict(data['input'])\n",
    "    return jsonify(predictions.tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb131af9-b555-4e3e-a798-17f9c5db843c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5001\n",
      " * Running on http://172.22.158.244:5001\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "app.run(host='0.0.0.0', port=5001)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
